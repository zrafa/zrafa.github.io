
Para cualquier arquitectura de computadoras existen, por lo general, 
muchas implementaciones con diferentes precios y rendimiento.
El diseñador debe, en cada implementación, seleccionar una estructura
de computadora que cumpla con restricciones de costos y que, a su vez,
tenga el mejor rendimiento y confiabilidad posible. 
Esta estructura debe ser construida con tecnologías de componentes 
fácilmente disponibles y, tipicamente, debe poder ser modificable para
aceptar nuevas tecnologías.

En la rápida evolución que han tenido las computadoras en las ultimas decadas,
el costo de la memoria ha sido el mayor factor en el precio general del 
sistema.
Aunque las memorias se hayan convertido tambien en elementos baratos
hay (y siempre habrán) memorias con variedad de capacidad de almacenamiento y 
características de rendimiento disponible, en diferentes costos.
Debido a que la velocidad de la memoria tiene una influencia sustancial
en la velocidad de ejecución de la CPU, seleccionar cada tecnología de memoria
particular, y organización general del sistema de memoria es un aspecto 
crítico al momento de diseñar un nuevo miembro de una familia de computadoras.

Si el costo no es una restricción, el sistema de memoria entero podría
ser construido utilizando la memoria disponible mas rápida, como se hizo
para la computadora CRAY-1, y como suele hacerse en las supercomputadoras,
donde el costo no es un problema.
Para computadoras de bajo costo, esto es obviamente imposible.
De cualquier manera, una opción para computadoras personales y sistemas
embebidos es organizar el sistema de memoria dentro de una jerarquía 
de niveles, donde cada nivel está compuesto de tecnologías de 
memorias diferentes (en cuanto a costo, capacidad y velocidad de acceso).
Esto puede hacerse debido al conocimiento existente, de las características
estadísticas de los patrones de acceso a memoria, que realizan 
programas típicos en ejecución.

La aproximación de la tecnología mas rápida

Una manera de estructurar el sistema de memoria total es implementar un 
segmento de la memoria con la tecnología mas rápida disponible.
Ejemplificando, suponga que en un sistema existen 64Kbytes de memoria
más rápida posible, en la cual el usuario puede completar con datos y código
ejecutable. El usuario puede entonces ubicar el código y los datos mas 
criticos en cuanto a tiempo de ejecución, en la memoria de alta velocidad, en tiempo de carga del programa. 
Esto le permite predecir el rendimiento y tiempo de ejecución con exactitud.
De cualquier manera, 
es improbable que este método beneficie a un sistema de tiempo compartido
(time-sharing system), en el cual la memoria física es asignada y reasignada
entre los usuarios durante distintos momentos (computadoras de propósito
general).
Otra desventaja de esta aproximación es que el programador debe
conocer la arquitectura de la memoria física para utilizarla correctamente.

Memoria Caché

La tecnología más común utilizada en un sistema de memoria de una computadora
es la memoria caché (pronunciado "cash", que proviene
del la palabra francés cacher, que siginifica "ocultar") en la jerarquía de memoria establecida.
La memoria caché es una memoria pequeña, costosa y de muy alta velocidad.
Se encuentra ubicada junto a la CPU y mantiene las instrucciones y datos
mas recientemente utilizados. Cuando un programa realiza un requisito 
a memoria, la CPU verifica primero si el dato está en la caché.
Si está, entonces el dato es traído rapidamente sin necesidad de utilizar
la memoria principal.
 Los programas no ejecutan instrucciones aleatoriamente. Mas bien,
exiben una probada localidad en la generación de direcciones y uso de la 
memoria. Por lo que la memoria generalmente es accesida en un orden 
lógico, frecuentemente secuencial (por ejemplo, cuando la CPU accede a las instrucciones del programa) o en zonas cercanas a direcciones recientemente
accedidas (cuado por ejemplo se procesa un arreglo de información).
Alternativamente, un programa podría repetidamente ejecutar un flujo
de instrucciones de un ciclo o bucle, y luego saltar a otra área del
programa en memoria.
En este caso, si la caché puede mantener suficientes datos para evitar
un gran número de referencias a la memoria principal, la velocidad
de ejecución incrementa substancialmente, y la utilizacion de la memoria
principal y del bus del sistema es también reducida beneficiosamente.

instrucciones
